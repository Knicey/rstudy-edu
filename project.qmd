---
title: "US Computer/Internet Use Census Supplement 2021"
format: pdf
editor: visual
editor_options: 
  chunk_output_type: console
---

## Libraries/Packages

```{r}
#| label: load-pkg-data
#| echo: false
#| message: false
#| warning: false
library(knitr) 
library(tidyverse)
library(patchwork)
library(dplyr)
library(stringr)
library(usmap)
library(maps)

```

```{r}
#| label: load-data
#| echo: false
#| message: false
comp_internet <- readr::read_csv('data/nov21pub.csv')
test_scores_cov <- readr::read_csv('data/seda2023_cov_state_annual.csv')
test_admindist_gys <- readr::read_csv('data/seda2023_admindist_poolsub_gys_updated_20240205.csv')
test_admindist_ys <- readr::read_csv('data/seda2023_admindist_poolsub_ys_updated_20240205.csv')
test_state_gys <- readr::read_csv('data/seda2023_state_poolsub_gys_updated_20240205.csv')
test_state_ys <- readr::read_csv('data/seda2023_state_poolsub_ys_updated_20240205.csv')
```

## EDA - Comp/Internet

This is a dataset corresponding to the November 2021 Census. This dataset in particular, has an additional supplement asking questions about Computer and Internet Use.

Documentation and dataset can be found here: <https://www.census.gov/data/datasets/time-series/demo/cps/cps-supp_cps-repwgt/cps-computer.html>

```{r}
#| label: data-factoring
#| echo: false
#| message: false
#glimpse(comp_internet)
col_names <- names(comp_internet)
col_names <- col_names[ !col_names == "GESTFIPS"]

#Pivot table probably not that useful since it anonymizes the questions from each other
comp_status <- comp_internet |>
  group_by( HUFINAL ) |>
  summarise( count = n() ) |>
  ungroup()

```

```{r}
#| label: comp_int_factor
#Making all variables factors
comp_internet <- comp_internet |>
  mutate(
    across(all_of(col_names), as.factor)
  )
```

The census imputes certain values for specific responses

-1 (blank)

-2 (don't know)

-3 (refused)

This dataset has 568 columns and 127,375 observations, each one representing a different interview.

```{r}
#| label: demographic-general-viz
#| echo: false
#| message: false
hufinal_total <- ggplot(comp_internet, aes(x = fct_infreq(HUFINAL), fill = HUFINAL)) +
  geom_bar() +
  labs(
    title = "Final Result (HUFINAL) Distribution",
    subtitle = "By the 2021 Census",
    y = "Count",
    x = "",
    caption = "CAPI stands for Computer-Assisted Personal Interviewing\nCATI stands for Computer-Assisted Telephone Interviewing"
  )

hufinal_total

hufinal_4 <- hufinal_total + 
  scale_x_discrete(
    limits = c("201", "218", "1", "226"), 
    labels=c( "REFUSED", "FULLY COMPLETE\nCATI INTERVIEW", "CAPI COMPLETE", "VACANT REGULAR")) 

#Separate dataframe for distribution counts
           
hufinal_4

#Note: The documentation is states that 0 is non-interview, but no 0s were recorded

ggplot(comp_internet, aes(x = fct_infreq(HUINTTYP), fill = HUINTTYP)) +
  geom_bar() +
  labs(
    title = "Interview Type",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "TELEPHONE", "PERSONAL", "NONINTERVIEW/INDETERMINATE" ))

ggplot(comp_internet, aes(x = fct_infreq(GEREG), fill = GEREG)) +
  geom_bar() +
  labs(
    title = "Distribution by Region",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "South", "West", "Midwest", "Northeast" ))
```

```{r}
#| label: supplement-question-viz
#| echo: false
desktop <- ggplot(comp_internet, aes(x = fct_infreq(HEDESKTP), fill = HEDESKTP)) +
  geom_bar() +
  labs(
    title = "Does someone in your house use a desktop computer?",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "No", "Yes", "blank"))
#"-1" = "No", etc.

desktop

laptop <- ggplot(comp_internet, aes(x = fct_infreq(HELAPTOP), fill = HELAPTOP)) +
  geom_bar() +
  labs(
    title = "Does someone in your house use a laptop?",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "Yes", "No", "blank"))

laptop

internet <- ggplot(comp_internet, aes(x = fct_infreq(HEINHOME), fill = HEINHOME)) +
  geom_bar() +
  labs(
    title = "Does someone in your house use the internet?",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "Yes", "blank", "No"))

internet

data_plan <- ggplot(comp_internet, aes(x = fct_infreq(HEMOBDAT), fill = HEMOBDAT)) +
  geom_bar() +
  labs(
    title = "Does someone in your house use a data plan?",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(labels = c( "Yes", "blank", "No"))

data_plan

internet+data_plan


ed_train <- ggplot(comp_internet, aes(x = PEEDTRAI, fill = PEEDTRAI)) +
  geom_bar() +
  labs(
    title = "Does someone in your house use the internet for online classes or job training?",
    y = "Count",
    x = ""
  ) + 
  scale_x_discrete(limits = c("1", "2"), labels = c( "Yes", "No"))

ed_train

#PRNMCHLD number of children might be correlated
```

## EDA - Test Scores

These are the test scores compiled by the Education Recovery Scorecard as part of The Educational Opportunity Project at Stanford University. They use the results of state-administered exams and adjust them to be comparable across subjects, grades, and or years.

The report can be found here: <https://educationrecoveryscorecard.org/wp-content/uploads/2024/01/ERS-Report-Final-1.31.pdf>

The datasets can be found here: <https://edopportunity.org/get-the-data/seda-archive-downloads/>

Documentation can be found here: <https://edopportunity.org/docs/seda2023_documentation_20240130.pdf>

Year Standardized (YS)

> To create the YS scale, we standardize the estimates to the 2019 national average in each grade and subject. In this scale, each unit is equivalent to a 2019 national standard deviation in the same subject and grade

Grade Year Standardized (GYS)

> To create the GYS scale, we first approximate the average amount student test scores grow in a grade on NAEP using the 4th and 8th grade estimates by subject in 2019. We calculate the amount the tests cores changed between 4th and 8th grade as the average score in 8th grade in 2019 minus the average score in 4th grade in 2019. Then, to get an estimate of per-grade differences, we divide that value by 4. We scale the data using these parameters, such that in the GYS scale each unit is interpretable as 1 grade level referenced to the 2019 national population.

Other important acronyms

`EB`: Empirical Bayes

`OLS`: Ordinary Least Squares

This dataset, test_admindist_gys has 72 columns and 40,897 observations, each observation representing

```{r}
#| echo: false
#| message: false

ggplot(test_admindist_ys |> filter(subject == "mth"), aes(x = ys_mn_2023_ol
) ) +
  geom_density() +
  labs(
    title = "Math Estimated Test Score Across-State"
  )

ggplot(test_admindist_ys |> filter(subject == "rla"), aes(x = ys_mn_2023_ol
) ) +
  geom_density() +
  labs(
    title = "Reading Estimated Test Score Across-State"
  )

test_state_ys_all_math <- filter(test_state_ys, subgroup == "all", subject == "mth")

test_admindist_ys_all_math_nc <- filter(test_admindist_ys, subgroup == "all", subject == "mth", stateabb == "NC")

ggplot(test_state_ys_all_math, aes(x = ys_mn_2022_ol
) ) +
  geom_density() +
  labs(
    title = "Reading Estimated Test Score Across-State"
  )

plot_usmap(data = test_state_ys_all_math, 
           values = "ys_mn_2022_ol"
           )

comp_internet_renamed <- comp_internet |> 
  rename(
    fips_state = GESTFIPS,
    fips_district = GTCO,
    ) 

comp_internet_renamed$fips_state

comp_internet_renamed <- comp_internet_renamed |>
  mutate(
    state_name = fips_info(fips_state)$full
  )

comp_internet_renamed$state_name

fips_info(3)$full

comp_internet_renamed$state_name

HEDESKTOP_state <- comp_internet_renamed |>
  group_by(state_name) |>
  summarise_at(vars(HEDESKTP), list(name = mean)) |>
  rename(
    avg = name,
    state = state_name
  )
```

To-do:

Look into additional datasets for additional factors affecting academic performance.

Look into bivariate color mapping

Shiny App Writeup:

-   Introduction/Sources/Goals

-   Look at existing dashboards to see what they include

Report (in quarto document/manuscript):

-   Intro

-   Methodology

    -   Papers/resources I looked at/

    -   Data curation

    -   Dashboard

    -   Model

    -   Explaining thought process and statistical methods

-   Results and Findings

-   Conclusions

-   Also think about publicity of the project

Final Deliverable:

Shiny Dashboard - Interactive Map

-   Different layers representing different data sets

    -   Additional factors layered on test scores

    -   Different filters

-   Model

    -   What factors impact change in scores/discrepancy between math and reading scores?

    -   Focusing on the effect of the pandemic
